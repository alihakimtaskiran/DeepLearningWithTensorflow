{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Single Layer Perceptron.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIsl-8y8qeVD",
        "colab_type": "code",
        "outputId": "0f26f9e5-9fa4-4e14-8a96-284b98023638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "mnist=input_data.read_data_sets(\"data/\",one_hot=True)\n",
        "\n",
        "X=tf.placeholder(tf.float32,[None,784])\n",
        "Y=tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "lr=1e-3\n",
        "batch_size=512\n",
        "\n",
        "W=tf.Variable(tf.random.truncated_normal([784,10],stddev=0.1),name=\"W\")\n",
        "b=tf.Variable(tf.zeros(10),name=\"b\")\n",
        "\n",
        "y=tf.nn.softmax(tf.linalg.matmul(X,W)+b)\n",
        "\n",
        "xent=-tf.reduce_sum(Y*tf.math.log(y))\n",
        "\n",
        "correct_pred=tf.equal(tf.argmax(Y,1),tf.argmax(y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\n",
        "optimizer=tf.train.AdamOptimizer(lr).minimize(xent)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(15000):\n",
        "    batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
        "    sess.run(optimizer,feed_dict={X:batch_x,Y:batch_y})\n",
        "    if i%100==0:\n",
        "      acc,loss=sess.run([accuracy,xent],feed_dict={X:batch_x,Y:batch_y})\n",
        "      print(\"Iteration\",i,\"Acc=\"+str(acc),\"Minibatch Loss=\"+str(loss))\n",
        "  test_acc,test_loss=sess.run([accuracy,xent],feed_dict={X:mnist.test.images,Y:mnist.test.labels})\n",
        "  print(\"Test Accuracy=\"+str(test_acc),\"Test Loss=\"+str(test_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "Iteration 0 Acc=0.123046875 Minibatch Loss=1308.7676\n",
            "Iteration 100 Acc=0.8359375 Minibatch Loss=373.40192\n",
            "Iteration 200 Acc=0.8828125 Minibatch Loss=247.91364\n",
            "Iteration 300 Acc=0.8886719 Minibatch Loss=229.79413\n",
            "Iteration 400 Acc=0.8964844 Minibatch Loss=199.5492\n",
            "Iteration 500 Acc=0.8847656 Minibatch Loss=190.6965\n",
            "Iteration 600 Acc=0.8886719 Minibatch Loss=217.58517\n",
            "Iteration 700 Acc=0.9160156 Minibatch Loss=139.23993\n",
            "Iteration 800 Acc=0.90625 Minibatch Loss=170.25925\n",
            "Iteration 900 Acc=0.92578125 Minibatch Loss=148.18411\n",
            "Iteration 1000 Acc=0.90625 Minibatch Loss=175.44531\n",
            "Iteration 1100 Acc=0.9277344 Minibatch Loss=145.29132\n",
            "Iteration 1200 Acc=0.9121094 Minibatch Loss=169.77545\n",
            "Iteration 1300 Acc=0.921875 Minibatch Loss=140.2486\n",
            "Iteration 1400 Acc=0.9121094 Minibatch Loss=161.56467\n",
            "Iteration 1500 Acc=0.91015625 Minibatch Loss=134.76639\n",
            "Iteration 1600 Acc=0.91796875 Minibatch Loss=140.81538\n",
            "Iteration 1700 Acc=0.9140625 Minibatch Loss=161.61432\n",
            "Iteration 1800 Acc=0.9042969 Minibatch Loss=198.26625\n",
            "Iteration 1900 Acc=0.92578125 Minibatch Loss=150.35402\n",
            "Iteration 2000 Acc=0.9316406 Minibatch Loss=127.286285\n",
            "Iteration 2100 Acc=0.93359375 Minibatch Loss=137.01825\n",
            "Iteration 2200 Acc=0.9238281 Minibatch Loss=150.61578\n",
            "Iteration 2300 Acc=0.9296875 Minibatch Loss=106.87007\n",
            "Iteration 2400 Acc=0.91796875 Minibatch Loss=159.22383\n",
            "Iteration 2500 Acc=0.91796875 Minibatch Loss=134.70575\n",
            "Iteration 2600 Acc=0.9199219 Minibatch Loss=123.51029\n",
            "Iteration 2700 Acc=0.9296875 Minibatch Loss=123.22072\n",
            "Iteration 2800 Acc=0.9375 Minibatch Loss=131.08371\n",
            "Iteration 2900 Acc=0.9394531 Minibatch Loss=127.870804\n",
            "Iteration 3000 Acc=0.9238281 Minibatch Loss=119.8179\n",
            "Iteration 3100 Acc=0.9277344 Minibatch Loss=118.8973\n",
            "Iteration 3200 Acc=0.9277344 Minibatch Loss=141.33185\n",
            "Iteration 3300 Acc=0.9472656 Minibatch Loss=106.68092\n",
            "Iteration 3400 Acc=0.9394531 Minibatch Loss=101.74111\n",
            "Iteration 3500 Acc=0.94140625 Minibatch Loss=130.04445\n",
            "Iteration 3600 Acc=0.9199219 Minibatch Loss=145.03317\n",
            "Iteration 3700 Acc=0.9355469 Minibatch Loss=134.4667\n",
            "Iteration 3800 Acc=0.9238281 Minibatch Loss=118.58329\n",
            "Iteration 3900 Acc=0.9394531 Minibatch Loss=121.40589\n",
            "Iteration 4000 Acc=0.9296875 Minibatch Loss=128.03867\n",
            "Iteration 4100 Acc=0.9433594 Minibatch Loss=125.42302\n",
            "Iteration 4200 Acc=0.9375 Minibatch Loss=120.62492\n",
            "Iteration 4300 Acc=0.9316406 Minibatch Loss=124.16196\n",
            "Iteration 4400 Acc=0.9394531 Minibatch Loss=115.782585\n",
            "Iteration 4500 Acc=0.9511719 Minibatch Loss=91.21174\n",
            "Iteration 4600 Acc=0.93359375 Minibatch Loss=108.09624\n",
            "Iteration 4700 Acc=0.94140625 Minibatch Loss=102.11887\n",
            "Iteration 4800 Acc=0.9355469 Minibatch Loss=138.76984\n",
            "Iteration 4900 Acc=0.9394531 Minibatch Loss=108.08658\n",
            "Iteration 5000 Acc=0.9394531 Minibatch Loss=122.73066\n",
            "Iteration 5100 Acc=0.9453125 Minibatch Loss=130.56575\n",
            "Iteration 5200 Acc=0.9453125 Minibatch Loss=95.717514\n",
            "Iteration 5300 Acc=0.92578125 Minibatch Loss=135.44672\n",
            "Iteration 5400 Acc=0.9433594 Minibatch Loss=98.042725\n",
            "Iteration 5500 Acc=0.94140625 Minibatch Loss=104.26814\n",
            "Iteration 5600 Acc=0.93359375 Minibatch Loss=130.1524\n",
            "Iteration 5700 Acc=0.9375 Minibatch Loss=111.41158\n",
            "Iteration 5800 Acc=0.91015625 Minibatch Loss=146.25467\n",
            "Iteration 5900 Acc=0.9433594 Minibatch Loss=121.8015\n",
            "Iteration 6000 Acc=0.93359375 Minibatch Loss=122.37205\n",
            "Iteration 6100 Acc=0.92578125 Minibatch Loss=130.98767\n",
            "Iteration 6200 Acc=0.94921875 Minibatch Loss=121.72201\n",
            "Iteration 6300 Acc=0.9375 Minibatch Loss=145.13998\n",
            "Iteration 6400 Acc=0.94140625 Minibatch Loss=120.95519\n",
            "Iteration 6500 Acc=0.9238281 Minibatch Loss=128.69656\n",
            "Iteration 6600 Acc=0.9199219 Minibatch Loss=143.79039\n",
            "Iteration 6700 Acc=0.9433594 Minibatch Loss=129.78645\n",
            "Iteration 6800 Acc=0.90234375 Minibatch Loss=158.92197\n",
            "Iteration 6900 Acc=0.92578125 Minibatch Loss=141.39014\n",
            "Iteration 7000 Acc=0.94140625 Minibatch Loss=110.670685\n",
            "Iteration 7100 Acc=0.94140625 Minibatch Loss=124.40651\n",
            "Iteration 7200 Acc=0.9453125 Minibatch Loss=92.704865\n",
            "Iteration 7300 Acc=0.92578125 Minibatch Loss=104.58887\n",
            "Iteration 7400 Acc=0.921875 Minibatch Loss=155.46155\n",
            "Iteration 7500 Acc=0.94140625 Minibatch Loss=118.39089\n",
            "Iteration 7600 Acc=0.9355469 Minibatch Loss=124.335365\n",
            "Iteration 7700 Acc=0.94140625 Minibatch Loss=106.15953\n",
            "Iteration 7800 Acc=0.94921875 Minibatch Loss=95.90414\n",
            "Iteration 7900 Acc=0.9589844 Minibatch Loss=101.49248\n",
            "Iteration 8000 Acc=0.94140625 Minibatch Loss=109.55712\n",
            "Iteration 8100 Acc=0.94921875 Minibatch Loss=106.929886\n",
            "Iteration 8200 Acc=0.9316406 Minibatch Loss=124.20001\n",
            "Iteration 8300 Acc=0.9316406 Minibatch Loss=131.28369\n",
            "Iteration 8400 Acc=0.9296875 Minibatch Loss=154.02217\n",
            "Iteration 8500 Acc=0.94921875 Minibatch Loss=102.54878\n",
            "Iteration 8600 Acc=0.9375 Minibatch Loss=130.59863\n",
            "Iteration 8700 Acc=0.953125 Minibatch Loss=94.90267\n",
            "Iteration 8800 Acc=0.9472656 Minibatch Loss=113.58372\n",
            "Iteration 8900 Acc=0.9296875 Minibatch Loss=124.4395\n",
            "Iteration 9000 Acc=0.94140625 Minibatch Loss=111.98511\n",
            "Iteration 9100 Acc=0.9433594 Minibatch Loss=103.627625\n",
            "Iteration 9200 Acc=0.9511719 Minibatch Loss=98.051865\n",
            "Iteration 9300 Acc=0.9550781 Minibatch Loss=89.12499\n",
            "Iteration 9400 Acc=0.9453125 Minibatch Loss=103.525055\n",
            "Iteration 9500 Acc=0.9433594 Minibatch Loss=131.54207\n",
            "Iteration 9600 Acc=0.9277344 Minibatch Loss=138.0622\n",
            "Iteration 9700 Acc=0.92578125 Minibatch Loss=150.3227\n",
            "Iteration 9800 Acc=0.9375 Minibatch Loss=131.82861\n",
            "Iteration 9900 Acc=0.9355469 Minibatch Loss=127.4953\n",
            "Iteration 10000 Acc=0.94140625 Minibatch Loss=109.1348\n",
            "Iteration 10100 Acc=0.92578125 Minibatch Loss=177.88014\n",
            "Iteration 10200 Acc=0.9238281 Minibatch Loss=143.02887\n",
            "Iteration 10300 Acc=0.9453125 Minibatch Loss=108.589294\n",
            "Iteration 10400 Acc=0.9453125 Minibatch Loss=96.51575\n",
            "Iteration 10500 Acc=0.9375 Minibatch Loss=115.90315\n",
            "Iteration 10600 Acc=0.94140625 Minibatch Loss=106.37252\n",
            "Iteration 10700 Acc=0.9472656 Minibatch Loss=79.138306\n",
            "Iteration 10800 Acc=0.9316406 Minibatch Loss=114.2777\n",
            "Iteration 10900 Acc=0.9375 Minibatch Loss=109.97241\n",
            "Iteration 11000 Acc=0.9238281 Minibatch Loss=148.98184\n",
            "Iteration 11100 Acc=0.94140625 Minibatch Loss=97.987305\n",
            "Iteration 11200 Acc=0.91796875 Minibatch Loss=125.2614\n",
            "Iteration 11300 Acc=0.9375 Minibatch Loss=113.069336\n",
            "Iteration 11400 Acc=0.9453125 Minibatch Loss=102.0107\n",
            "Iteration 11500 Acc=0.93359375 Minibatch Loss=108.92327\n",
            "Iteration 11600 Acc=0.9433594 Minibatch Loss=105.44605\n",
            "Iteration 11700 Acc=0.9433594 Minibatch Loss=132.28247\n",
            "Iteration 11800 Acc=0.91796875 Minibatch Loss=133.12184\n",
            "Iteration 11900 Acc=0.93359375 Minibatch Loss=100.88305\n",
            "Iteration 12000 Acc=0.94921875 Minibatch Loss=86.69205\n",
            "Iteration 12100 Acc=0.9453125 Minibatch Loss=118.89674\n",
            "Iteration 12200 Acc=0.93359375 Minibatch Loss=121.139305\n",
            "Iteration 12300 Acc=0.9511719 Minibatch Loss=117.03536\n",
            "Iteration 12400 Acc=0.9433594 Minibatch Loss=111.20035\n",
            "Iteration 12500 Acc=0.9453125 Minibatch Loss=103.419785\n",
            "Iteration 12600 Acc=0.9316406 Minibatch Loss=128.07014\n",
            "Iteration 12700 Acc=0.9316406 Minibatch Loss=126.78134\n",
            "Iteration 12800 Acc=0.9433594 Minibatch Loss=115.51134\n",
            "Iteration 12900 Acc=0.9296875 Minibatch Loss=138.2213\n",
            "Iteration 13000 Acc=0.9355469 Minibatch Loss=117.98115\n",
            "Iteration 13100 Acc=0.9375 Minibatch Loss=121.639275\n",
            "Iteration 13200 Acc=0.9511719 Minibatch Loss=103.851204\n",
            "Iteration 13300 Acc=0.9316406 Minibatch Loss=131.0763\n",
            "Iteration 13400 Acc=0.9453125 Minibatch Loss=95.19136\n",
            "Iteration 13500 Acc=0.9375 Minibatch Loss=146.84283\n",
            "Iteration 13600 Acc=0.9316406 Minibatch Loss=157.93488\n",
            "Iteration 13700 Acc=0.9277344 Minibatch Loss=116.51058\n",
            "Iteration 13800 Acc=0.93359375 Minibatch Loss=136.341\n",
            "Iteration 13900 Acc=0.9375 Minibatch Loss=120.341835\n",
            "Iteration 14000 Acc=0.9453125 Minibatch Loss=126.4719\n",
            "Iteration 14100 Acc=0.9589844 Minibatch Loss=94.42667\n",
            "Iteration 14200 Acc=0.94921875 Minibatch Loss=91.72142\n",
            "Iteration 14300 Acc=0.9394531 Minibatch Loss=94.043335\n",
            "Iteration 14400 Acc=0.9511719 Minibatch Loss=84.105515\n",
            "Iteration 14500 Acc=0.94140625 Minibatch Loss=128.55727\n",
            "Iteration 14600 Acc=0.9511719 Minibatch Loss=94.32718\n",
            "Iteration 14700 Acc=0.921875 Minibatch Loss=155.45007\n",
            "Iteration 14800 Acc=0.9453125 Minibatch Loss=105.98839\n",
            "Iteration 14900 Acc=0.9316406 Minibatch Loss=116.77808\n",
            "Test Accuracy=0.9286 Test Loss=2712.9282\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
