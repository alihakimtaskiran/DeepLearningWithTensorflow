{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi Layer Perceptron.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZcVXliA5v9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f50a47fc-5fa3-488a-fc68-b2a63219f9a7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "mnist=input_data.read_data_sets(\"data/\",one_hot=True)\n",
        "\n",
        "X=tf.placeholder(tf.float32,[None,784])\n",
        "Y=tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "lr=1e-3\n",
        "batch_size=512\n",
        "\n",
        "layer0=784\n",
        "layer1=256\n",
        "layer2=128\n",
        "layer3=64\n",
        "layer4=32\n",
        "layer_out=10\n",
        "\n",
        "W0=tf.Variable(tf.random.truncated_normal([layer0,layer1],stddev=0.1),name=\"W0\")\n",
        "b0=tf.Variable(tf.zeros(layer1),name=\"b0\")\n",
        "\n",
        "W1=tf.Variable(tf.random.truncated_normal([layer1,layer2],stddev=0.1),name=\"W1\")\n",
        "b1=tf.Variable(tf.zeros(layer2),name=\"b1\")\n",
        "\n",
        "W2=tf.Variable(tf.random.truncated_normal([layer2,layer3],stddev=0.1),name=\"W2\")\n",
        "b2=tf.Variable(tf.zeros(layer3),name=\"b2\")\n",
        "\n",
        "W3=tf.Variable(tf.random.truncated_normal([layer3,layer4],stddev=0.1),name=\"W3\")\n",
        "b3=tf.Variable(tf.zeros(layer4),name=\"b3\")\n",
        "\n",
        "W_out=tf.Variable(tf.random.truncated_normal([layer4,layer_out],stddev=0.1),name=\"W_out\")\n",
        "b_out=tf.Variable(tf.zeros(10),name=\"b_out\")\n",
        "\n",
        "\n",
        "y0=tf.nn.tanh(tf.linalg.matmul(X,W0)+b0)\n",
        "y1=tf.nn.tanh(tf.linalg.matmul(y0,W1)+b1)\n",
        "y2=tf.nn.tanh(tf.linalg.matmul(y1,W2)+b2)\n",
        "y3=tf.nn.tanh(tf.linalg.matmul(y2,W3)+b3)\n",
        "y=tf.nn.softmax(tf.linalg.matmul(y3,W_out)+b_out)\n",
        "\n",
        "xent=-tf.reduce_sum(Y*tf.math.log(y))\n",
        "\n",
        "correct_pred=tf.equal(tf.argmax(Y,1),tf.argmax(y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\n",
        "optimizer=tf.train.AdamOptimizer(lr).minimize(xent)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(15000):\n",
        "    batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
        "    sess.run(optimizer,feed_dict={X:batch_x,Y:batch_y})\n",
        "    if i%100==0:\n",
        "      acc,loss=sess.run([accuracy,xent],feed_dict={X:batch_x,Y:batch_y})\n",
        "      print(\"Iteration\",i,\"Acc=\"+str(acc),\"Minibatch Loss=\"+str(loss))\n",
        "  test_acc,test_loss=sess.run([accuracy,xent],feed_dict={X:mnist.test.images,Y:mnist.test.labels})\n",
        "  print(\"Test Accuracy=\"+str(test_acc),\"Test Loss=\"+str(test_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "Iteration 0 Acc=0.22070312 Minibatch Loss=1146.843\n",
            "Iteration 100 Acc=0.91015625 Minibatch Loss=209.3111\n",
            "Iteration 200 Acc=0.9433594 Minibatch Loss=116.85279\n",
            "Iteration 300 Acc=0.9765625 Minibatch Loss=60.920418\n",
            "Iteration 400 Acc=0.9824219 Minibatch Loss=44.511215\n",
            "Iteration 500 Acc=0.98046875 Minibatch Loss=38.526947\n",
            "Iteration 600 Acc=0.9863281 Minibatch Loss=27.881607\n",
            "Iteration 700 Acc=0.9863281 Minibatch Loss=20.726017\n",
            "Iteration 800 Acc=0.99609375 Minibatch Loss=13.0030775\n",
            "Iteration 900 Acc=0.99609375 Minibatch Loss=18.400246\n",
            "Iteration 1000 Acc=0.9980469 Minibatch Loss=6.3218884\n",
            "Iteration 1100 Acc=1.0 Minibatch Loss=4.142916\n",
            "Iteration 1200 Acc=0.9980469 Minibatch Loss=6.184335\n",
            "Iteration 1300 Acc=1.0 Minibatch Loss=4.9258823\n",
            "Iteration 1400 Acc=0.9980469 Minibatch Loss=9.137085\n",
            "Iteration 1500 Acc=0.9980469 Minibatch Loss=3.844479\n",
            "Iteration 1600 Acc=1.0 Minibatch Loss=3.1923416\n",
            "Iteration 1700 Acc=1.0 Minibatch Loss=2.1279578\n",
            "Iteration 1800 Acc=0.9980469 Minibatch Loss=4.8249083\n",
            "Iteration 1900 Acc=1.0 Minibatch Loss=1.0009077\n",
            "Iteration 2000 Acc=1.0 Minibatch Loss=1.2475356\n",
            "Iteration 2100 Acc=0.9980469 Minibatch Loss=3.7327862\n",
            "Iteration 2200 Acc=0.9980469 Minibatch Loss=4.678735\n",
            "Iteration 2300 Acc=1.0 Minibatch Loss=1.8805784\n",
            "Iteration 2400 Acc=1.0 Minibatch Loss=1.5384138\n",
            "Iteration 2500 Acc=1.0 Minibatch Loss=0.98834777\n",
            "Iteration 2600 Acc=1.0 Minibatch Loss=0.43986082\n",
            "Iteration 2700 Acc=1.0 Minibatch Loss=0.5752916\n",
            "Iteration 2800 Acc=1.0 Minibatch Loss=0.45981118\n",
            "Iteration 2900 Acc=1.0 Minibatch Loss=0.3002982\n",
            "Iteration 3000 Acc=1.0 Minibatch Loss=0.26709706\n",
            "Iteration 3100 Acc=1.0 Minibatch Loss=0.22141796\n",
            "Iteration 3200 Acc=1.0 Minibatch Loss=0.24418724\n",
            "Iteration 3300 Acc=1.0 Minibatch Loss=0.25174928\n",
            "Iteration 3400 Acc=1.0 Minibatch Loss=0.22411\n",
            "Iteration 3500 Acc=1.0 Minibatch Loss=0.13901904\n",
            "Iteration 3600 Acc=1.0 Minibatch Loss=0.14272597\n",
            "Iteration 3700 Acc=1.0 Minibatch Loss=0.16014385\n",
            "Iteration 3800 Acc=1.0 Minibatch Loss=0.15572536\n",
            "Iteration 3900 Acc=1.0 Minibatch Loss=0.12478167\n",
            "Iteration 4000 Acc=1.0 Minibatch Loss=0.1378176\n",
            "Iteration 4100 Acc=1.0 Minibatch Loss=0.1379156\n",
            "Iteration 4200 Acc=1.0 Minibatch Loss=0.14983408\n",
            "Iteration 4300 Acc=1.0 Minibatch Loss=0.111172155\n",
            "Iteration 4400 Acc=1.0 Minibatch Loss=0.10291549\n",
            "Iteration 4500 Acc=1.0 Minibatch Loss=0.122550614\n",
            "Iteration 4600 Acc=1.0 Minibatch Loss=0.0945449\n",
            "Iteration 4700 Acc=1.0 Minibatch Loss=0.0736074\n",
            "Iteration 4800 Acc=1.0 Minibatch Loss=0.064707845\n",
            "Iteration 4900 Acc=1.0 Minibatch Loss=0.07222314\n",
            "Iteration 5000 Acc=1.0 Minibatch Loss=0.06672017\n",
            "Iteration 5100 Acc=1.0 Minibatch Loss=0.12250866\n",
            "Iteration 5200 Acc=1.0 Minibatch Loss=0.05408676\n",
            "Iteration 5300 Acc=1.0 Minibatch Loss=0.061645728\n",
            "Iteration 5400 Acc=1.0 Minibatch Loss=0.061246283\n",
            "Iteration 5500 Acc=1.0 Minibatch Loss=0.05457792\n",
            "Iteration 5600 Acc=1.0 Minibatch Loss=0.035581917\n",
            "Iteration 5700 Acc=1.0 Minibatch Loss=0.04153884\n",
            "Iteration 5800 Acc=1.0 Minibatch Loss=0.078329206\n",
            "Iteration 5900 Acc=1.0 Minibatch Loss=0.038336813\n",
            "Iteration 6000 Acc=1.0 Minibatch Loss=0.04621897\n",
            "Iteration 6100 Acc=1.0 Minibatch Loss=0.030073868\n",
            "Iteration 6200 Acc=1.0 Minibatch Loss=0.029516604\n",
            "Iteration 6300 Acc=1.0 Minibatch Loss=0.028342975\n",
            "Iteration 6400 Acc=1.0 Minibatch Loss=0.030080369\n",
            "Iteration 6500 Acc=1.0 Minibatch Loss=0.030021299\n",
            "Iteration 6600 Acc=1.0 Minibatch Loss=0.02584963\n",
            "Iteration 6700 Acc=1.0 Minibatch Loss=0.031542107\n",
            "Iteration 6800 Acc=1.0 Minibatch Loss=0.019158134\n",
            "Iteration 6900 Acc=1.0 Minibatch Loss=0.020665966\n",
            "Iteration 7000 Acc=1.0 Minibatch Loss=0.016845847\n",
            "Iteration 7100 Acc=1.0 Minibatch Loss=0.016441599\n",
            "Iteration 7200 Acc=1.0 Minibatch Loss=0.02043627\n",
            "Iteration 7300 Acc=1.0 Minibatch Loss=0.018978179\n",
            "Iteration 7400 Acc=1.0 Minibatch Loss=0.01807704\n",
            "Iteration 7500 Acc=1.0 Minibatch Loss=0.01746912\n",
            "Iteration 7600 Acc=1.0 Minibatch Loss=0.019238459\n",
            "Iteration 7700 Acc=1.0 Minibatch Loss=0.013892842\n",
            "Iteration 7800 Acc=1.0 Minibatch Loss=0.015088533\n",
            "Iteration 7900 Acc=1.0 Minibatch Loss=0.0113894055\n",
            "Iteration 8000 Acc=1.0 Minibatch Loss=0.012578515\n",
            "Iteration 8100 Acc=1.0 Minibatch Loss=0.014603196\n",
            "Iteration 8200 Acc=1.0 Minibatch Loss=0.012035703\n",
            "Iteration 8300 Acc=1.0 Minibatch Loss=0.011333667\n",
            "Iteration 8400 Acc=1.0 Minibatch Loss=0.010699898\n",
            "Iteration 8500 Acc=1.0 Minibatch Loss=0.0097410325\n",
            "Iteration 8600 Acc=1.0 Minibatch Loss=0.009110931\n",
            "Iteration 8700 Acc=1.0 Minibatch Loss=0.00839551\n",
            "Iteration 8800 Acc=1.0 Minibatch Loss=0.010207012\n",
            "Iteration 8900 Acc=1.0 Minibatch Loss=0.008858519\n",
            "Iteration 9000 Acc=1.0 Minibatch Loss=0.010304337\n",
            "Iteration 9100 Acc=1.0 Minibatch Loss=0.008637612\n",
            "Iteration 9200 Acc=1.0 Minibatch Loss=0.006402698\n",
            "Iteration 9300 Acc=1.0 Minibatch Loss=0.0058785034\n",
            "Iteration 9400 Acc=1.0 Minibatch Loss=0.0057724947\n",
            "Iteration 9500 Acc=1.0 Minibatch Loss=0.0053822794\n",
            "Iteration 9600 Acc=1.0 Minibatch Loss=0.005181249\n",
            "Iteration 9700 Acc=1.0 Minibatch Loss=0.0042090463\n",
            "Iteration 9800 Acc=1.0 Minibatch Loss=0.004699576\n",
            "Iteration 9900 Acc=1.0 Minibatch Loss=0.004811225\n",
            "Iteration 10000 Acc=1.0 Minibatch Loss=0.004025733\n",
            "Iteration 10100 Acc=1.0 Minibatch Loss=0.004969012\n",
            "Iteration 10200 Acc=1.0 Minibatch Loss=0.004069344\n",
            "Iteration 10300 Acc=1.0 Minibatch Loss=0.003559075\n",
            "Iteration 10400 Acc=1.0 Minibatch Loss=0.004564047\n",
            "Iteration 10500 Acc=1.0 Minibatch Loss=0.0033503114\n",
            "Iteration 10600 Acc=1.0 Minibatch Loss=0.004315922\n",
            "Iteration 10700 Acc=1.0 Minibatch Loss=0.002892645\n",
            "Iteration 10800 Acc=1.0 Minibatch Loss=0.0029743114\n",
            "Iteration 10900 Acc=1.0 Minibatch Loss=0.0025601648\n",
            "Iteration 11000 Acc=1.0 Minibatch Loss=0.0026990091\n",
            "Iteration 11100 Acc=1.0 Minibatch Loss=0.0024525223\n",
            "Iteration 11200 Acc=1.0 Minibatch Loss=0.0023758681\n",
            "Iteration 11300 Acc=1.0 Minibatch Loss=0.0021808336\n",
            "Iteration 11400 Acc=1.0 Minibatch Loss=0.002357509\n",
            "Iteration 11500 Acc=1.0 Minibatch Loss=0.0020855893\n",
            "Iteration 11600 Acc=1.0 Minibatch Loss=0.0018376284\n",
            "Iteration 11700 Acc=1.0 Minibatch Loss=0.001643666\n",
            "Iteration 11800 Acc=1.0 Minibatch Loss=0.0015989654\n",
            "Iteration 11900 Acc=1.0 Minibatch Loss=0.0019312226\n",
            "Iteration 12000 Acc=1.0 Minibatch Loss=0.0015367442\n",
            "Iteration 12100 Acc=1.0 Minibatch Loss=0.0015386444\n",
            "Iteration 12200 Acc=1.0 Minibatch Loss=0.0014779645\n",
            "Iteration 12300 Acc=1.0 Minibatch Loss=0.0013455244\n",
            "Iteration 12400 Acc=1.0 Minibatch Loss=0.0010429659\n",
            "Iteration 12500 Acc=1.0 Minibatch Loss=0.0012890159\n",
            "Iteration 12600 Acc=1.0 Minibatch Loss=0.0011030474\n",
            "Iteration 12700 Acc=1.0 Minibatch Loss=0.0010885056\n",
            "Iteration 12800 Acc=1.0 Minibatch Loss=0.0008649844\n",
            "Iteration 12900 Acc=1.0 Minibatch Loss=0.0009477167\n",
            "Iteration 13000 Acc=1.0 Minibatch Loss=0.00095689774\n",
            "Iteration 13100 Acc=1.0 Minibatch Loss=0.0008583092\n",
            "Iteration 13200 Acc=1.0 Minibatch Loss=0.0008289857\n",
            "Iteration 13300 Acc=1.0 Minibatch Loss=0.0008003745\n",
            "Iteration 13400 Acc=1.0 Minibatch Loss=0.00082111615\n",
            "Iteration 13500 Acc=1.0 Minibatch Loss=0.00072121894\n",
            "Iteration 13600 Acc=1.0 Minibatch Loss=0.0006383676\n",
            "Iteration 13700 Acc=1.0 Minibatch Loss=0.00062716124\n",
            "Iteration 13800 Acc=1.0 Minibatch Loss=0.0007090598\n",
            "Iteration 13900 Acc=1.0 Minibatch Loss=0.00060165033\n",
            "Iteration 14000 Acc=1.0 Minibatch Loss=0.00050306425\n",
            "Iteration 14100 Acc=1.0 Minibatch Loss=0.00075646583\n",
            "Iteration 14200 Acc=1.0 Minibatch Loss=0.0004581217\n",
            "Iteration 14300 Acc=1.0 Minibatch Loss=0.00044655855\n",
            "Iteration 14400 Acc=1.0 Minibatch Loss=0.00045490358\n",
            "Iteration 14500 Acc=1.0 Minibatch Loss=0.00037980126\n",
            "Iteration 14600 Acc=1.0 Minibatch Loss=0.00045478437\n",
            "Iteration 14700 Acc=1.0 Minibatch Loss=0.00035023718\n",
            "Iteration 14800 Acc=1.0 Minibatch Loss=0.00040352426\n",
            "Iteration 14900 Acc=1.0 Minibatch Loss=0.0003465418\n",
            "Test Accuracy=0.9809 Test Loss=1470.6101\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
